{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d36adef5",
   "metadata": {},
   "source": [
    "# Leitura do arquivo e configurações iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "442c5b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./titanic.csv\n",
      "./jupyter_local.ipynb\n",
      "./lista4_eng.pdf\n",
      "./winequality.zip\n",
      "./winequality/winequalityN.csv\n",
      "./.ipynb_checkpoints/jupyter_local-checkpoint.ipynb\n",
      "./codigo_teste/weather_prevision.py\n",
      "./codigo_teste/weatherAUS.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>white</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>white</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>white</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>white</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0  white            7.0              0.27         0.36            20.7   \n",
       "1  white            6.3              0.30         0.34             1.6   \n",
       "2  white            8.1              0.28         0.40             6.9   \n",
       "3  white            7.2              0.23         0.32             8.5   \n",
       "4  white            7.2              0.23         0.32             8.5   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0      0.045                 45.0                 170.0   1.0010  3.00   \n",
       "1      0.049                 14.0                 132.0   0.9940  3.30   \n",
       "2      0.050                 30.0                  97.0   0.9951  3.26   \n",
       "3      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "4      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "\n",
       "   sulphates  alcohol  quality  \n",
       "0       0.45      8.8        6  \n",
       "1       0.49      9.5        6  \n",
       "2       0.44     10.1        6  \n",
       "3       0.40      9.9        6  \n",
       "4       0.40      9.9        6  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importa o dataset\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "\n",
    "history = []\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('.'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        \n",
    "nome_arquivo = './winequality/winequalityN.csv'\n",
    "df=pd.read_csv(nome_arquivo) # Leitura do arquivo\n",
    "df.head() # Visualização do arquivo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fd4e9959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes: 6497 linhas\n",
      "Depois: 6463 linhas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.068</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.99651</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6463 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0        1            7.0             0.270         0.36            20.7   \n",
       "1        1            6.3             0.300         0.34             1.6   \n",
       "2        1            8.1             0.280         0.40             6.9   \n",
       "3        1            7.2             0.230         0.32             8.5   \n",
       "4        1            7.2             0.230         0.32             8.5   \n",
       "...    ...            ...               ...          ...             ...   \n",
       "6491     0            6.8             0.620         0.08             1.9   \n",
       "6492     0            6.2             0.600         0.08             2.0   \n",
       "6494     0            6.3             0.510         0.13             2.3   \n",
       "6495     0            5.9             0.645         0.12             2.0   \n",
       "6496     0            6.0             0.310         0.47             3.6   \n",
       "\n",
       "      chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0         0.045                 45.0                 170.0  1.00100  3.00   \n",
       "1         0.049                 14.0                 132.0  0.99400  3.30   \n",
       "2         0.050                 30.0                  97.0  0.99510  3.26   \n",
       "3         0.058                 47.0                 186.0  0.99560  3.19   \n",
       "4         0.058                 47.0                 186.0  0.99560  3.19   \n",
       "...         ...                  ...                   ...      ...   ...   \n",
       "6491      0.068                 28.0                  38.0  0.99651  3.42   \n",
       "6492      0.090                 32.0                  44.0  0.99490  3.45   \n",
       "6494      0.076                 29.0                  40.0  0.99574  3.42   \n",
       "6495      0.075                 32.0                  44.0  0.99547  3.57   \n",
       "6496      0.067                 18.0                  42.0  0.99549  3.39   \n",
       "\n",
       "      sulphates  alcohol  quality  \n",
       "0          0.45      8.8        6  \n",
       "1          0.49      9.5        6  \n",
       "2          0.44     10.1        6  \n",
       "3          0.40      9.9        6  \n",
       "4          0.40      9.9        6  \n",
       "...         ...      ...      ...  \n",
       "6491       0.82      9.5        6  \n",
       "6492       0.58     10.5        5  \n",
       "6494       0.75     11.0        6  \n",
       "6495       0.71     10.2        5  \n",
       "6496       0.66     11.0        6  \n",
       "\n",
       "[6463 rows x 13 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove as linhas com dados vazios\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(\"Antes:\", len(df.index) ,\"linhas\")\n",
    "\n",
    "\n",
    "temp_data = df\n",
    "le = LabelEncoder()\n",
    "temp_data['type'] = le.fit_transform(temp_data['type'])\n",
    "new_df = temp_data.dropna()\n",
    "print(\"Depois:\", len(new_df.index), \"linhas\")\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "909628de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 1.5.2\n",
      "numpy: 1.25.0\n",
      "sklearn: 1.2.0\n"
     ]
    }
   ],
   "source": [
    "# Importa várias bibliotecas importantes\n",
    "# Tensorflow / Keras\n",
    "\n",
    "import tensorflow as tf # used to access argmax function\n",
    "from tensorflow import keras # for building Neural Networks\n",
    "#print('Tensorflow/Keras: %s' % keras.__version__) # print version\n",
    "from keras.models import Sequential # for creating a linear stack of layers for our Neural Network\n",
    "from keras import Input # for instantiating a keras tensor\n",
    "from keras.layers import Dense, BatchNormalization # for creating regular densely-connected NN layer.\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd # for data manipulation\n",
    "print('pandas: %s' % pd.__version__) # print version\n",
    "import numpy as np # for data manipulation\n",
    "print('numpy: %s' % np.__version__) # print version\n",
    "\n",
    "# Sklearn\n",
    "import sklearn # for model evaluation\n",
    "print('sklearn: %s' % sklearn.__version__) # print version\n",
    "from sklearn.metrics import classification_report # for model evaluation metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2981d91f",
   "metadata": {},
   "source": [
    "# Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "109f4b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa o dataset entre treino e teste\n",
    "def dataset_split():\n",
    "    # O atributo quality será utilizado como o verificador (r(valor_correto) - y(previsão))\n",
    "    X= new_df.drop([\"quality\"] ,axis= 1)\n",
    "    Y = new_df[['quality']]\n",
    "\n",
    "    # Separa o dataset entre treino e teste. Sendo a proporção de 70% para o treino e 30% para o teste)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size = 0.3, random_state = 0)\n",
    "#     print(\"Shape of X_train: \", X_train.shape)\n",
    "#     print(\"Shape of y_train: \", Y_train.shape)\n",
    "#     print(\"Shape of X_test: \", X_test.shape)\n",
    "#     print(\"Shape of y_test: \", Y_test.shape)\n",
    "    return (X_train, Y_train, X_test, Y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "46c293ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelagem da rede neural\n",
    "\n",
    "\n",
    "def ann_model(number_of_layers, minimum, maximum, input_size):\n",
    "    model = Sequential(name = \"DFF-Model\")\n",
    "\n",
    "    # Adiciona o input com normalização\n",
    "    model.add(Input(shape=(input_size), name = 'Input-Layer'))\n",
    "    model.add(BatchNormalization(synchronized=True))\n",
    "\n",
    "    # Cria as hidden layers com batch normalization e relu\n",
    "    for i in range(number_of_layers):\n",
    "#         number_of_neurons = 32\n",
    "#         if(i%2==0):\n",
    "#             number_of_neurons = 64\n",
    "        number_of_neurons = random.randint(minimum,maximum)\n",
    "        name = 'Hidden-Layer-' + str(i)\n",
    "        model.add(Dense(number_of_neurons, activation = 'relu', name = name))\n",
    "        model.add(BatchNormalization(synchronized=True))\n",
    "\n",
    "\n",
    "    model.add(Dense(11, activation = 'softmax', name = 'output'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "21c870a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compila o modelo\n",
    "def compile_the_model(model):\n",
    "    # determina a função de perda\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='SparseCategoricalCrossentropy',\n",
    "                  metrics=['Accuracy'],\n",
    "                  run_eagerly=None, # Defaults to False. If True, this Model's logic will not be wrapped in a tf.function. Recommended to leave this as None unless your Model cannot be run inside a tf.function.\n",
    "                  steps_per_execution=None # Defaults to 1. The number of batches to run during each tf.function call. Running multiple batches inside a single tf.function call can greatly improve performance on TPUs or small models with a large Python overhead.\n",
    "                 )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2dd0a7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina o modelo.\n",
    "def train_model(model,X_train, Y_train):\n",
    "    \n",
    "    # Condição de parada caso não haja melhora na acurácia dos dados de validação nas últimas 5 verificações.\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience = 5)\n",
    "\n",
    "    model.fit(\n",
    "        x=X_train,\n",
    "        y=Y_train,\n",
    "        #batch_size=None,\n",
    "        epochs= 100,\n",
    "        verbose=0,#verbose='auto',\n",
    "        callbacks=None,\n",
    "        validation_split=0.2, # tamanho do dataset de validação\n",
    "        #validation_data=None,\n",
    "        shuffle=True,\n",
    "        class_weight=None,\n",
    "        sample_weight=None,\n",
    "        initial_epoch=0,\n",
    "        steps_per_epoch=None,\n",
    "        validation_steps=None,\n",
    "        validation_batch_size=None,\n",
    "        validation_freq=3,\n",
    "        max_queue_size=10,\n",
    "        workers=1,\n",
    "        use_multiprocessing=False\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c59d2d",
   "metadata": {},
   "source": [
    "# Acurácia do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ab54a045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna a acurácia do modelo\n",
    "def accuracy_analysis(y_test, y_pred, name):\n",
    "    return  accuracy_score(y_test,y_pred)*100\n",
    "    \n",
    "\n",
    "def model_accuracy(model,X_train, Y_train,X_test,Y_test):\n",
    "\n",
    "    # Predict class labels on training data\n",
    "    pred_labels_tr = np.array(tf.math.argmax(model.predict(X_train),axis=1))\n",
    "    # Predict class labels on a test data\n",
    "    pred_labels_te = np.array(tf.math.argmax(model.predict(X_test),axis=1))\n",
    "    tr_ac = accuracy_analysis(Y_train, pred_labels_tr,\"training\")\n",
    "    tst_ac = accuracy_analysis(Y_test, pred_labels_te,\"test\")\n",
    "  \n",
    "    return (tr_ac,tst_ac)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "532f458b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 598us/step\n",
      "61/61 [==============================] - 0s 601us/step\n",
      "(2, 2, 4, 54.664014146772764, 53.99690562145436)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 546us/step\n",
      "61/61 [==============================] - 0s 577us/step\n",
      "(2, 3, 6, 54.70822281167109, 54.10005157297576)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 544us/step\n",
      "61/61 [==============================] - 0s 555us/step\n",
      "(2, 4, 8, 56.808134394341295, 54.46106240330067)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 548us/step\n",
      "61/61 [==============================] - 0s 571us/step\n",
      "(2, 5, 10, 58.17860300618921, 56.627127385250134)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 551us/step\n",
      "61/61 [==============================] - 0s 561us/step\n",
      "(2, 6, 12, 57.802829354553495, 54.667354306343476)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 547us/step\n",
      "61/61 [==============================] - 0s 560us/step\n",
      "(2, 7, 14, 58.775419982316535, 55.23465703971119)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 535us/step\n",
      "61/61 [==============================] - 0s 552us/step\n",
      "(2, 8, 16, 56.98496905393458, 55.492521918514704)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 544us/step\n",
      "61/61 [==============================] - 0s 565us/step\n",
      "(2, 9, 18, 58.53227232537578, 55.3378029912326)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 561us/step\n",
      "61/61 [==============================] - 0s 575us/step\n",
      "(3, 2, 4, 55.725022104332446, 53.842186694172256)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 608us/step\n",
      "61/61 [==============================] - 0s 647us/step\n",
      "(3, 3, 6, 55.83554376657824, 54.82207323362558)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 565us/step\n",
      "61/61 [==============================] - 0s 550us/step\n",
      "(3, 4, 8, 56.58709106984969, 54.151624548736464)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 566us/step\n",
      "61/61 [==============================] - 0s 564us/step\n",
      "(3, 5, 10, 56.896551724137936, 54.770500257864875)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 561us/step\n",
      "61/61 [==============================] - 0s 577us/step\n",
      "(3, 6, 12, 57.824933687002655, 54.976792160907685)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 561us/step\n",
      "61/61 [==============================] - 0s 568us/step\n",
      "(3, 7, 14, 58.64279398762158, 55.6988138215575)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 567us/step\n",
      "61/61 [==============================] - 0s 562us/step\n",
      "(3, 8, 16, 58.09018567639257, 54.71892728210418)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 566us/step\n",
      "61/61 [==============================] - 0s 570us/step\n",
      "(3, 9, 18, 59.88063660477454, 56.52398143372873)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 601us/step\n",
      "61/61 [==============================] - 0s 588us/step\n",
      "(4, 2, 4, 56.122900088417325, 54.56420835482207)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 572us/step\n",
      "61/61 [==============================] - 0s 579us/step\n",
      "(4, 3, 6, 55.260831122900086, 54.25477050025786)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 592us/step\n",
      "61/61 [==============================] - 0s 602us/step\n",
      "(4, 4, 8, 56.58709106984969, 56.111397627643115)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 601us/step\n",
      "61/61 [==============================] - 0s 639us/step\n",
      "(4, 5, 10, 55.90185676392573, 54.04847859721505)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 590us/step\n",
      "61/61 [==============================] - 0s 589us/step\n",
      "(4, 6, 12, 58.37754199823165, 55.286230015471894)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 586us/step\n",
      "61/61 [==============================] - 0s 594us/step\n",
      "(4, 7, 14, 59.06277630415562, 55.3378029912326)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 595us/step\n",
      "61/61 [==============================] - 0s 585us/step\n",
      "(4, 8, 16, 58.841732979664016, 55.183084063950496)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 585us/step\n",
      "61/61 [==============================] - 0s 620us/step\n",
      "(4, 9, 18, 58.09018567639257, 55.440948942754)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 606us/step\n",
      "61/61 [==============================] - 0s 581us/step\n",
      "(5, 2, 4, 55.37135278514589, 54.87364620938629)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 612us/step\n",
      "61/61 [==============================] - 0s 590us/step\n",
      "(5, 3, 6, 56.29973474801061, 54.10005157297576)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 588us/step\n",
      "61/61 [==============================] - 0s 570us/step\n",
      "(5, 4, 8, 56.16710875331565, 56.00825167612171)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 593us/step\n",
      "61/61 [==============================] - 0s 593us/step\n",
      "(5, 5, 10, 57.228116710875334, 55.3378029912326)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 588us/step\n",
      "61/61 [==============================] - 0s 575us/step\n",
      "(5, 6, 12, 57.53757736516357, 54.71892728210418)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 602us/step\n",
      "61/61 [==============================] - 0s 582us/step\n",
      "(5, 7, 14, 58.99646330680813, 54.71892728210418)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 591us/step\n",
      "61/61 [==============================] - 0s 605us/step\n",
      "(5, 8, 16, 58.797524314765695, 55.38937596699329)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 657us/step\n",
      "61/61 [==============================] - 0s 637us/step\n",
      "(5, 9, 18, 59.01856763925729, 55.3378029912326)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 614us/step\n",
      "61/61 [==============================] - 0s 579us/step\n",
      "(6, 2, 4, 55.57029177718833, 54.82207323362558)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 628us/step\n",
      "61/61 [==============================] - 0s 683us/step\n",
      "(6, 3, 6, 55.45977011494253, 55.544094894275396)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 637us/step\n",
      "61/61 [==============================] - 0s 649us/step\n",
      "(6, 4, 8, 56.18921308576481, 55.07993811242908)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 621us/step\n",
      "61/61 [==============================] - 0s 617us/step\n",
      "(6, 5, 10, 57.55968169761273, 55.07993811242908)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 622us/step\n",
      "61/61 [==============================] - 0s 594us/step\n",
      "(6, 6, 12, 57.44916003536693, 54.667354306343476)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 637us/step\n",
      "61/61 [==============================] - 0s 630us/step\n",
      "(6, 7, 14, 58.863837312113176, 54.25477050025786)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 618us/step\n",
      "61/61 [==============================] - 0s 621us/step\n",
      "(6, 8, 16, 56.94076038903625, 55.440948942754)\n",
      "----------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 623us/step\n",
      "61/61 [==============================] - 0s 630us/step\n",
      "(6, 9, 18, 57.824933687002655, 54.82207323362558)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 641us/step\n",
      "61/61 [==============================] - 0s 626us/step\n",
      "(7, 2, 4, 54.35455349248453, 53.17173800928313)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 638us/step\n",
      "61/61 [==============================] - 0s 631us/step\n",
      "(7, 3, 6, 54.48717948717948, 53.945332645693654)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 614us/step\n",
      "61/61 [==============================] - 0s 602us/step\n",
      "(7, 4, 8, 56.01237842617153, 54.92521918514698)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 640us/step\n",
      "61/61 [==============================] - 0s 606us/step\n",
      "(7, 5, 10, 56.233421750663126, 55.5956678700361)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 664us/step\n",
      "61/61 [==============================] - 0s 660us/step\n",
      "(7, 6, 12, 57.55968169761273, 55.286230015471894)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 658us/step\n",
      "61/61 [==============================] - 0s 633us/step\n",
      "(7, 7, 14, 57.692307692307686, 53.842186694172256)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 643us/step\n",
      "61/61 [==============================] - 0s 655us/step\n",
      "(7, 8, 16, 57.51547303271442, 54.30634347601857)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "142/142 [==============================] - 0s 657us/step\n",
      "61/61 [==============================] - 0s 620us/step\n",
      "(7, 9, 18, 58.59858532272325, 55.6988138215575)\n",
      "----------------------------------\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2, 2, 4, 54.664014146772764, 53.99690562145436),\n",
       " (2, 3, 6, 54.70822281167109, 54.10005157297576),\n",
       " (2, 4, 8, 56.808134394341295, 54.46106240330067),\n",
       " (2, 5, 10, 58.17860300618921, 56.627127385250134),\n",
       " (2, 6, 12, 57.802829354553495, 54.667354306343476),\n",
       " (2, 7, 14, 58.775419982316535, 55.23465703971119),\n",
       " (2, 8, 16, 56.98496905393458, 55.492521918514704),\n",
       " (2, 9, 18, 58.53227232537578, 55.3378029912326),\n",
       " (3, 2, 4, 55.725022104332446, 53.842186694172256),\n",
       " (3, 3, 6, 55.83554376657824, 54.82207323362558),\n",
       " (3, 4, 8, 56.58709106984969, 54.151624548736464),\n",
       " (3, 5, 10, 56.896551724137936, 54.770500257864875),\n",
       " (3, 6, 12, 57.824933687002655, 54.976792160907685),\n",
       " (3, 7, 14, 58.64279398762158, 55.6988138215575),\n",
       " (3, 8, 16, 58.09018567639257, 54.71892728210418),\n",
       " (3, 9, 18, 59.88063660477454, 56.52398143372873),\n",
       " (4, 2, 4, 56.122900088417325, 54.56420835482207),\n",
       " (4, 3, 6, 55.260831122900086, 54.25477050025786),\n",
       " (4, 4, 8, 56.58709106984969, 56.111397627643115),\n",
       " (4, 5, 10, 55.90185676392573, 54.04847859721505),\n",
       " (4, 6, 12, 58.37754199823165, 55.286230015471894),\n",
       " (4, 7, 14, 59.06277630415562, 55.3378029912326),\n",
       " (4, 8, 16, 58.841732979664016, 55.183084063950496),\n",
       " (4, 9, 18, 58.09018567639257, 55.440948942754),\n",
       " (5, 2, 4, 55.37135278514589, 54.87364620938629),\n",
       " (5, 3, 6, 56.29973474801061, 54.10005157297576),\n",
       " (5, 4, 8, 56.16710875331565, 56.00825167612171),\n",
       " (5, 5, 10, 57.228116710875334, 55.3378029912326),\n",
       " (5, 6, 12, 57.53757736516357, 54.71892728210418),\n",
       " (5, 7, 14, 58.99646330680813, 54.71892728210418),\n",
       " (5, 8, 16, 58.797524314765695, 55.38937596699329),\n",
       " (5, 9, 18, 59.01856763925729, 55.3378029912326),\n",
       " (6, 2, 4, 55.57029177718833, 54.82207323362558),\n",
       " (6, 3, 6, 55.45977011494253, 55.544094894275396),\n",
       " (6, 4, 8, 56.18921308576481, 55.07993811242908),\n",
       " (6, 5, 10, 57.55968169761273, 55.07993811242908),\n",
       " (6, 6, 12, 57.44916003536693, 54.667354306343476),\n",
       " (6, 7, 14, 58.863837312113176, 54.25477050025786),\n",
       " (6, 8, 16, 56.94076038903625, 55.440948942754),\n",
       " (6, 9, 18, 57.824933687002655, 54.82207323362558),\n",
       " (7, 2, 4, 54.35455349248453, 53.17173800928313),\n",
       " (7, 3, 6, 54.48717948717948, 53.945332645693654),\n",
       " (7, 4, 8, 56.01237842617153, 54.92521918514698),\n",
       " (7, 5, 10, 56.233421750663126, 55.5956678700361),\n",
       " (7, 6, 12, 57.55968169761273, 55.286230015471894),\n",
       " (7, 7, 14, 57.692307692307686, 53.842186694172256),\n",
       " (7, 8, 16, 57.51547303271442, 54.30634347601857),\n",
       " (7, 9, 18, 58.59858532272325, 55.6988138215575)]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Procura qual a melhor arquitetura por brute force\n",
    "\n",
    "best = []\n",
    "melhor = 0\n",
    "for i in range(2,8):\n",
    "    for k in range(2,10):\n",
    "#       for j in range(3):\n",
    "        number_of_layers = (i)\n",
    "        minimum = k\n",
    "        maximum = minimum*2\n",
    "\n",
    "\n",
    "        (X_train, Y_train,X_test,Y_test) = dataset_split()\n",
    "        model = ann_model(number_of_layers, minimum , maximum, X_train.shape[1])\n",
    "        model = compile_the_model(model)\n",
    "        model = train_model(model, X_train, Y_train)\n",
    "        (tr_ac,tst_ac) = model_accuracy(model, X_train, Y_train,X_test,Y_test)\n",
    "\n",
    "\n",
    "\n",
    "        history.append((number_of_layers, minimum , maximum,tr_ac,tst_ac))\n",
    "        if(tst_ac > melhor):\n",
    "            melhor = tst_ac\n",
    "            best_model = model\n",
    "            best_dataset = [X_train, Y_train, X_test, Y_test]\n",
    "        print(history[-1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        print(\"----------------------------------\\n\\n\")\n",
    "        \n",
    "    print(\"----------------------------------\")\n",
    "    print(\"----------------------------------\")\n",
    "    print(\"----------------------------------\\n\\n\")\n",
    "\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ca252e",
   "metadata": {},
   "source": [
    "## Impressão da melhor arquitetura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43054557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_analysis2(y_test, y_pred, name):\n",
    "      \n",
    "    print(\"Confusion Matrix: \",\n",
    "        confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print (\"Accuracy : \",\n",
    "    accuracy_score(y_test,y_pred)*100)\n",
    "    \n",
    "    \n",
    "    print(\"Report : \",\n",
    "    classification_report(y_test, y_pred, zero_division=0))\n",
    "   \n",
    "    \n",
    "def model_accuracy2(model,X_train, Y_train,X_test,Y_test):\n",
    "\n",
    "    # Predict class labels on training data\n",
    "    pred_labels_tr = np.array(tf.math.argmax(model.predict(X_train),axis=1))\n",
    "    # Predict class labels on a test data\n",
    "    pred_labels_te = np.array(tf.math.argmax(model.predict(X_test),axis=1))\n",
    "\n",
    "    ##### Step 5 - Model Performance Summary\n",
    "    print(\"\")\n",
    "    print('-------------------- Model Summary --------------------')\n",
    "    model.summary()\n",
    "    print(\"\")\n",
    "    \n",
    "    print(\"\")\n",
    "    print('---------- Evaluation on Training Data ----------')\n",
    "    accuracy_analysis2(Y_train, pred_labels_tr,\"training\")\n",
    "    \n",
    "\n",
    "    print('---------- Evaluation on Test Data ----------')\n",
    "    accuracy_analysis2(Y_test, pred_labels_te,\"test\") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f0b7e681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 574us/step\n",
      "61/61 [==============================] - 0s 585us/step\n",
      "\n",
      "-------------------- Model Summary --------------------\n",
      "Model: \"DFF-Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_3282 (  (None, 12)                48        \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " Hidden-Layer-0 (Dense)      (None, 10)                130       \n",
      "                                                                 \n",
      " batch_normalization_3283 (  (None, 10)                40        \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " Hidden-Layer-1 (Dense)      (None, 10)                110       \n",
      "                                                                 \n",
      " batch_normalization_3284 (  (None, 10)                40        \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " output (Dense)              (None, 11)                121       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 489 (1.91 KB)\n",
      "Trainable params: 425 (1.66 KB)\n",
      "Non-trainable params: 64 (256.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "---------- Evaluation on Training Data ----------\n",
      "Confusion Matrix:  [[   0    0    0    0    0    0    0    0]\n",
      " [   1    2    2    7    6    0    0    0]\n",
      " [   0    1   17   95   44    0    0    0]\n",
      " [   0    0    8  918  551   15    0    0]\n",
      " [   0    0    4  363 1443  147    0    0]\n",
      " [   0    0    0   18  480  252    0    0]\n",
      " [   0    0    0    1   81   65    0    0]\n",
      " [   0    0    0    0    1    2    0    0]]\n",
      "Accuracy :  58.17860300618921\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.67      0.11      0.19        18\n",
      "           4       0.55      0.11      0.18       157\n",
      "           5       0.65      0.62      0.63      1492\n",
      "           6       0.55      0.74      0.63      1957\n",
      "           7       0.52      0.34      0.41       750\n",
      "           8       0.00      0.00      0.00       147\n",
      "           9       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.58      4524\n",
      "   macro avg       0.37      0.24      0.26      4524\n",
      "weighted avg       0.56      0.58      0.56      4524\n",
      "\n",
      "---------- Evaluation on Test Data ----------\n",
      "Confusion Matrix:  [[  0   0   8   4   0   0   0]\n",
      " [  0   4  31  21   1   0   0]\n",
      " [  0   6 386 237   7   0   0]\n",
      " [  0   0 175 618  70   0   0]\n",
      " [  0   0   4 229  90   1   0]\n",
      " [  0   0   0  28  17   0   0]\n",
      " [  0   0   0   0   2   0   0]]\n",
      "Accuracy :  56.627127385250134\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00        12\n",
      "           4       0.40      0.07      0.12        57\n",
      "           5       0.64      0.61      0.62       636\n",
      "           6       0.54      0.72      0.62       863\n",
      "           7       0.48      0.28      0.35       324\n",
      "           8       0.00      0.00      0.00        45\n",
      "           9       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.57      1939\n",
      "   macro avg       0.29      0.24      0.24      1939\n",
      "weighted avg       0.54      0.57      0.54      1939\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = best_dataset [0]\n",
    "Y_train = best_dataset [1]\n",
    "X_test = best_dataset [2]\n",
    "Y_test = best_dataset [3]\n",
    "model_accuracy2(best_model, X_train, Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5516036f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
